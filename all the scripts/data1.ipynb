{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf841767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Real AI Analysis Setup Complete!\n",
      "‚úÖ Loaded dataset with 169 rows and 40 columns\n",
      "üìã Columns: ['SL NO', 'DOCTOR_NAME', 'HOSPITAL_NUMBER', 'PATIENT_NAME', 'CONTACTNO', 'DEATH/ ALIVE (7 AUG 2024)', 'DEATH/ ALIVE (OUTSIDE RX DETAILS)', 'status', 'FOLLOW UP STATUS', 'SURGERY DATE', 'Study end time', 'Calculation Time', 'time_in_days', 'time_in_mos', 'TUMOR SIZE', 'SEX', 'AGE', 'LOCATION', 'LOCATION.1', 'LATARALITY', 'HPR DETAILS', 'HPR', 'GRADE', 'PRESS_DIAGNOSIS', 'SURGERY NAME', 'SURGERY TYPE', 'GFAP', 'IDH1/ IDH2', 'ATRX', 'MGMT', 'Mib Lebeling Index', 'RT DOSE', 'RT MODALITY', 'CCRT', 'RT COMPLETION DATE', 'ADJUVANT ChT', 'START DATE', 'END DATE', 'RECC STATUS', 'OS']\n",
      "\n",
      "üîç Testing AI analysis: What are the main patterns and insights in this dataset?\n",
      "üîç Asking AI: What are the main patterns and insights in this dataset?\n",
      "üìä AI Response: The main patterns and insights in this dataset can be summarized as follows:\n",
      "\n",
      "1. The dataset contains a total of 36 patients with different types of brain tumors, including gliomas (20 patients), astrocytomas (15 patients), ependymomas (7 patients), and medulloblastomas (4 patients).\n",
      "\n",
      "2. The patients were divided into two groups based on their age: younger adults (aged 18-39 years) and older adults (aged 40 years or above).\n",
      "\n",
      "3. The patients' gender was equally distributed between male and female, with a total of 15 males and 21 females.\n",
      "\n",
      "4. The dataset includes information on the patient's age, sex, tumor type, grade, stage, and treatment (either surgery or radiation therapy).\n",
      "\n",
      "5. The median follow-up time for patients who underwent surgery was 3 years, while it was 2 years for those who received radiation therapy.\n",
      "\n",
      "6. The patients' overall survival rate was higher in the surgery group than in the radiation therapy group (80% vs. 57%).\n",
      "\n",
      "7. The median OS rate for patients who underwent surgery was 39 months, while it was 24 months for those who received radiation therapy.\n",
      "\n",
      "8. The median PFS rate for patients who underwent surgery was 21 months, while it was 10 months for those who received radiation therapy.\n",
      "\n",
      "9. The overall response rates (ORR) were higher in the surgery group than in the radiation therapy group (73% vs. 46%).\n",
      "\n",
      "10. The median OS rate for patients with a positive PET scan was 25 months, while it was 18 months for those without a positive PET scan.\n",
      "\n",
      "11. The median PFS rate for patients with a positive PET scan was 13 months, while it was 7 months for those without a positive PET scan.\n",
      "\n",
      "12. The overall response rates (ORR) were higher in the surgery group than in the radiation therapy group for patients with a positive PET scan (80% vs. 46%).\n",
      "\n",
      "13. The median OS rate for patients who underwent chemotherapy was 19 months, while it was 12 months for those who received radiation therapy.\n",
      "\n",
      "14. The median PFS rate for patients who underwent chemotherapy was 8 months, while it was 5 months for those who received radiation therapy.\n",
      "\n",
      "15. The overall response rates (ORR) were higher in the chemotherapy group than in the radiation therapy group for patients with a positive PET scan (70% vs. 46%).\n",
      "‚è±Ô∏è Time: 60.0 seconds\n",
      "\n",
      "üéâ Ready for AI Analysis!\n",
      "\n",
      "üí° You can now ask any question using:\n",
      "   ask_ai_question('Your question here', df)\n",
      "\n",
      "Example questions:\n",
      "- 'Is there a relationship between age and survival?'\n",
      "- 'What are the key factors affecting patient outcomes?'\n",
      "- 'Analyze the gender distribution and its implications'\n",
      "- 'What patterns do you see in the tumor size data?'\n",
      "- 'How do different surgery types relate to survival rates?'\n",
      "\n",
      "üîç Your question: Is there any missing values?\n",
      "üîç Asking AI: Is there any missing values?\n",
      "üìä AI Response: Yes, there are some missing values in the dataset. Specifically, there are missing values for the following columns:\n",
      "\n",
      "- Tumor size (HPR): \"TUMOR SIZE\" is a categorical variable with multiple possible values, but no corresponding numerical value has been provided. This could potentially cause issues when analyzing the data and interpreting the results.\n",
      "- Pressure diagnostics (GFAP): \"Pressure Diagnostics\" is a quantitative variable that contains numeric values, but there are no corresponding categorical values for this variable. This could affect the interpretation of the results and may lead to incorrect conclusions.\n",
      "- Supratentorial tumor (HPR): \"Supratentorial Tumor\" is a qualitative variable with multiple possible values, but no corresponding numerical value has been provided. This could potentially cause issues when analyzing the data and interpreting the results.\n",
      "\n",
      "To analyze the dataset more accurately, it would be helpful to provide additional information about these missing values. For example:\n",
      "\n",
      "- If \"TUMOR SIZE\" is a categorical variable with multiple possible values, can you provide a breakdown of the missing values for each category? This could help identify which categories are most affected by missing data and potentially inform strategies for addressing these issues.\n",
      "- If \"Pressure Diagnostics\" is a quantitative variable with numeric values, can you provide a breakdown of the missing values by category or type of pressure diagnostic (e.g., \"GFAP\", \"MIB2A\", etc.)? This could help identify which types of pressure diagnostics are most affected by missing data and potentially inform strategies for addressing these issues.\n",
      "- If \"Supratentorial Tumor\" is a qualitative variable with multiple possible values, can you provide a breakdown of the missing values by category or type of supratentorial tumor (e.g., \"Atypical High Grade\", \"Mixed Grade\", etc.)? This could help identify which types of supratentorial tumors are most affected by missing data and potentially inform strategies for addressing these issues.\n",
      "\n",
      "By providing this additional information, the analysis can be more accurate and relevant to the specific needs of the researcher or clinician working with this dataset.\n",
      "‚è±Ô∏è Time: 45.4 seconds\n",
      "\n",
      "‚úÖ AI analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# ===== REAL AI SOLUTION FOR NOTEBOOK =====\n",
    "# Copy this into your notebook for actual AI analysis\n",
    "\n",
    "# ===== CELL 1: Import and Setup =====\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "print(\"üöÄ Real AI Analysis Setup Complete!\")\n",
    "\n",
    "# ===== CELL 2: Load Any Dataset =====\n",
    "def load_any_dataset(file_path):\n",
    "    \"\"\"Load any dataset (Excel, CSV, etc.)\"\"\"\n",
    "    try:\n",
    "        if file_path.endswith('.xlsx') or file_path.endswith('.xls'):\n",
    "            df = pd.read_excel(file_path)\n",
    "        elif file_path.endswith('.csv'):\n",
    "            df = pd.read_csv(file_path)\n",
    "        else:\n",
    "            print(\"‚ùå Unsupported file format. Use Excel (.xlsx) or CSV (.csv)\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"‚úÖ Loaded dataset with {len(df)} rows and {len(df.columns)} columns\")\n",
    "        print(f\"üìã Columns: {list(df.columns)}\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading dataset: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load your dataset\n",
    "file_path = r\"D:\\Python code\\ollama\\GBM_V1.11.xlsx\"  # Change this to your file\n",
    "df = load_any_dataset(file_path)\n",
    "\n",
    "# ===== CELL 3: AI Analysis Function =====\n",
    "def ask_ai_question(question, df, model=\"tinyllama:latest\"):\n",
    "    \"\"\"Ask any question to AI about the dataset\"\"\"\n",
    "    try:\n",
    "        # Get comprehensive data summary\n",
    "        summary = {\n",
    "            \"total_rows\": len(df),\n",
    "            \"total_columns\": len(df.columns),\n",
    "            \"column_names\": list(df.columns),\n",
    "            \"data_types\": df.dtypes.to_dict(),\n",
    "            \"missing_values\": df.isnull().sum().to_dict(),\n",
    "            \"numeric_columns\": df.select_dtypes(include=['number']).columns.tolist(),\n",
    "            \"categorical_columns\": df.select_dtypes(include=['object']).columns.tolist(),\n",
    "            \"sample_data\": df.head(3).to_dict('records')\n",
    "        }\n",
    "        \n",
    "        # Create detailed prompt with actual data\n",
    "        prompt = f\"\"\"\n",
    "        I have a dataset with the following characteristics:\n",
    "        \n",
    "        DATASET INFO:\n",
    "        - Total rows: {summary['total_rows']}\n",
    "        - Total columns: {summary['total_columns']}\n",
    "        - Column names: {summary['column_names']}\n",
    "        - Data types: {summary['data_types']}\n",
    "        - Missing values: {summary['missing_values']}\n",
    "        - Numeric columns: {summary['numeric_columns']}\n",
    "        - Categorical columns: {summary['categorical_columns']}\n",
    "        \n",
    "        SAMPLE DATA (first 3 rows):\n",
    "        {summary['sample_data']}\n",
    "        \n",
    "        USER QUESTION: {question}\n",
    "        \n",
    "        Please analyze this dataset and provide insights based on the actual data. \n",
    "        Be specific and reference the actual column names and data.\n",
    "        \"\"\"\n",
    "        \n",
    "        # API call to model\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"stream\": False,\n",
    "            \"options\": {\n",
    "                \"num_ctx\": 1024,\n",
    "                \"num_thread\": 4,\n",
    "                \"temperature\": 0.3\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        print(f\"üîç Asking AI: {question}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        response = requests.post(\n",
    "            \"http://localhost:11434/api/chat\",\n",
    "            json=payload,\n",
    "            timeout=60\n",
    "        )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            content = data.get(\"message\", {}).get(\"content\", \"No response\")\n",
    "            print(f\"üìä AI Response: {content}\")\n",
    "            print(f\"‚è±Ô∏è Time: {end_time - start_time:.1f} seconds\")\n",
    "            return content\n",
    "        else:\n",
    "            print(f\"‚ùå Error: HTTP {response.status_code}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# ===== CELL 4: Test AI Analysis =====\n",
    "# Test with a real question\n",
    "if df is not None:\n",
    "    question = \"What are the main patterns and insights in this dataset?\"\n",
    "    print(f\"\\nüîç Testing AI analysis: {question}\")\n",
    "    ask_ai_question(question, df)\n",
    "\n",
    "# ===== CELL 5: Ready for Your Questions =====\n",
    "print(\"\\nüéâ Ready for AI Analysis!\")\n",
    "print(\"\\nüí° You can now ask any question using:\")\n",
    "print(\"   ask_ai_question('Your question here', df)\")\n",
    "print(\"\\nExample questions:\")\n",
    "print(\"- 'Is there a relationship between age and survival?'\")\n",
    "print(\"- 'What are the key factors affecting patient outcomes?'\")\n",
    "print(\"- 'Analyze the gender distribution and its implications'\")\n",
    "print(\"- 'What patterns do you see in the tumor size data?'\")\n",
    "print(\"- 'How do different surgery types relate to survival rates?'\")\n",
    "\n",
    "# ===== CELL 6: Ask Your Own Question =====\n",
    "# Change this question to whatever you want to analyze\n",
    "your_question = \"Is there any missing values?\"\n",
    "print(f\"\\nüîç Your question: {your_question}\")\n",
    "ask_ai_question(your_question, df)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n‚úÖ AI analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d9a064b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Your question: Can you check for a regression analysis between age and survival?\n",
      "üîç Asking AI: Can you check for a regression analysis between age and survival?\n",
      "üìä AI Response: Yes, we can conduct a regression analysis to see if there is a correlation between age and survival in the dataset. To perform this analysis, we will use the \"survminer\" package from R, which provides built-in support for regression analysis.\n",
      "\n",
      "Here's how we can set up the regression analysis:\n",
      "\n",
      "1. Import the dataset into R using the \"read.csv()\" function and store it as a data frame called \"data\".\n",
      "\n",
      "2. Split the data into training and testing sets using the \"split\" function from the \"strsplit\" package. We will use 70% of the data for training and the remaining 30% for testing.\n",
      "\n",
      "3. Calculate the mean survival time for each age group in the training set.\n",
      "\n",
      "4. Split the training set into age groups using the \"cut\" function from the \"strsplit\" package. We will use a cutoff of 65 years and divide the data into two groups: one with ages between 65-70 and another with ages between 71-80.\n",
      "\n",
      "5. Calculate the mean survival time for each age group in the training set, as well as the mean survival time for the entire training set.\n",
      "\n",
      "6. Create a regression model using \"survminer\" package from R. We will use the \"lm()\" function to fit a linear regression model with age as the dependent variable and survival time as the independent variable.\n",
      "\n",
      "7. Calculate the coefficient of determination (R^2) and adjusted R^2 for each age group.\n",
      "\n",
      "8. Plot the regression line for each age group, along with the actual survival data points.\n",
      "\n",
      "9. Perform a visual inspection of the regression lines to identify any trends or patterns in the data.\n",
      "\n",
      "10. Analyze the results and draw conclusions based on the regression analysis.\n",
      "‚è±Ô∏è Time: 42.4 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, we can conduct a regression analysis to see if there is a correlation between age and survival in the dataset. To perform this analysis, we will use the \"survminer\" package from R, which provides built-in support for regression analysis.\\n\\nHere\\'s how we can set up the regression analysis:\\n\\n1. Import the dataset into R using the \"read.csv()\" function and store it as a data frame called \"data\".\\n\\n2. Split the data into training and testing sets using the \"split\" function from the \"strsplit\" package. We will use 70% of the data for training and the remaining 30% for testing.\\n\\n3. Calculate the mean survival time for each age group in the training set.\\n\\n4. Split the training set into age groups using the \"cut\" function from the \"strsplit\" package. We will use a cutoff of 65 years and divide the data into two groups: one with ages between 65-70 and another with ages between 71-80.\\n\\n5. Calculate the mean survival time for each age group in the training set, as well as the mean survival time for the entire training set.\\n\\n6. Create a regression model using \"survminer\" package from R. We will use the \"lm()\" function to fit a linear regression model with age as the dependent variable and survival time as the independent variable.\\n\\n7. Calculate the coefficient of determination (R^2) and adjusted R^2 for each age group.\\n\\n8. Plot the regression line for each age group, along with the actual survival data points.\\n\\n9. Perform a visual inspection of the regression lines to identify any trends or patterns in the data.\\n\\n10. Analyze the results and draw conclusions based on the regression analysis.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "your_question = \"Can you check for a regression analysis between age and survival?\"\n",
    "print(f\"\\nüîç Your question: {your_question}\")\n",
    "ask_ai_question(your_question, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e18c680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Your question: Can you do this?\n",
      "üîç Asking AI: Can you do this?\n",
      "üìä AI Response: Sure, I can analyze this dataset and provide insights based on the actual column names and data. The dataset contains patient information, including demographic details, medical history, and treatment information. Some of the columns include patient ID, age, sex, disease type (e.g., astrocytoma, glioblastoma), tumor location (parieto-temporal or left parieto-occipital), grade (grade I-II), treatment type (surgery/radiation/chemotherapy), and follow-up date.\n",
      "\n",
      "To analyze this dataset, we can first check the column names to ensure they are correct. The \"ID\" column is the primary key for each patient record, so it should be named ID instead of id or patient_id. We can also check if there are any duplicate values in the data by comparing the unique values with the list of all unique values.\n",
      "\n",
      "Next, we can analyze the treatment information to see which treatments were given and how they were administered. For example, we can look at the \"Radiation\" column and compare it to the corresponding \"Surgery\" column. We can also check if there are any missing or incomplete data in this column.\n",
      "\n",
      "To analyze the medical history, we can look for any unusual patterns or changes over time. For example, we might notice that some patients have had multiple surgeries or radiation treatments within a short period of time. This could be an indication of complications or side effects from these treatments.\n",
      "\n",
      "Finally, to analyze the patient demographic information, we can check if there are any missing or incomplete data. For example, we might notice that some patients have missing information about their sex or race. This could indicate that they were not fully informed about their treatment options or had limited access to healthcare services.\n",
      "\n",
      "Overall, this dataset provides valuable insights into the patient's medical history and treatment information. By analyzing these data, we can gain a better understanding of the patient's needs, preferences, and overall health status.\n",
      "‚è±Ô∏è Time: 44.0 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sure, I can analyze this dataset and provide insights based on the actual column names and data. The dataset contains patient information, including demographic details, medical history, and treatment information. Some of the columns include patient ID, age, sex, disease type (e.g., astrocytoma, glioblastoma), tumor location (parieto-temporal or left parieto-occipital), grade (grade I-II), treatment type (surgery/radiation/chemotherapy), and follow-up date.\\n\\nTo analyze this dataset, we can first check the column names to ensure they are correct. The \"ID\" column is the primary key for each patient record, so it should be named ID instead of id or patient_id. We can also check if there are any duplicate values in the data by comparing the unique values with the list of all unique values.\\n\\nNext, we can analyze the treatment information to see which treatments were given and how they were administered. For example, we can look at the \"Radiation\" column and compare it to the corresponding \"Surgery\" column. We can also check if there are any missing or incomplete data in this column.\\n\\nTo analyze the medical history, we can look for any unusual patterns or changes over time. For example, we might notice that some patients have had multiple surgeries or radiation treatments within a short period of time. This could be an indication of complications or side effects from these treatments.\\n\\nFinally, to analyze the patient demographic information, we can check if there are any missing or incomplete data. For example, we might notice that some patients have missing information about their sex or race. This could indicate that they were not fully informed about their treatment options or had limited access to healthcare services.\\n\\nOverall, this dataset provides valuable insights into the patient\\'s medical history and treatment information. By analyzing these data, we can gain a better understanding of the patient\\'s needs, preferences, and overall health status.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "your_question = \"Can you do this?\"\n",
    "print(f\"\\nüîç Your question: {your_question}\")\n",
    "ask_ai_question(your_question, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d22249ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Your question: No. i meant can you do the regreesion analysis and share the result with me? If you can generate graphs and tables then it would be a bonus.\n",
      "üîç Asking AI: No. i meant can you do the regreesion analysis and share the result with me? If you can generate graphs and tables then it would be a bonus.\n",
      "üìä AI Response: To perform a regression analysis in Python, you can use the `statsmodels` library. Here's an example:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "from statsmodels.formula import reg\n",
      "\n",
      "# Load dataset\n",
      "data = pd.read_csv('dataset.csv')\n",
      "X = data[['age', 'sex', 'education', 'income']]\n",
      "y = data['salary']\n",
      "\n",
      "# Split into training and testing sets\n",
      "train, test = X[:500], X[500:]\n",
      "\n",
      "# Fit model using training set\n",
      "model = reg(X=train.drop('salary', axis=1), y=train['salary'])\n",
      "model.fit()\n",
      "\n",
      "# Evaluate model on testing set\n",
      "score = model.score(test, 'salary')\n",
      "print(f'Regression score: {score}')\n",
      "```\n",
      "\n",
      "In this example, we loaded the `dataset.csv` dataset and split it into training and testing sets with a ratio of 50% for each. We then fit the model using the training set and evaluate its performance on the testing set by computing the regression score. The result is printed to the console.\n",
      "\n",
      "To generate graphs and tables based on the actual data, you can use the `pandas` library. Here's an example:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "from statsmodels.formula import reg\n",
      "\n",
      "# Load dataset\n",
      "data = pd.read_csv('dataset.csv')\n",
      "X = data[['age', 'sex', 'education', 'income']]\n",
      "y = data['salary']\n",
      "\n",
      "# Fit model using training set\n",
      "model = reg(X=train.drop('salary', axis=1), y=train['salary'])\n",
      "model.summary()\n",
      "```\n",
      "\n",
      "In this example, we loaded the `dataset.csv` dataset and fitted a regression model using the training set. We then printed out the summary of the model using the `summary()` method.\n",
      "‚è±Ô∏è Time: 44.9 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"To perform a regression analysis in Python, you can use the `statsmodels` library. Here's an example:\\n\\n```python\\nimport pandas as pd\\nfrom statsmodels.formula import reg\\n\\n# Load dataset\\ndata = pd.read_csv('dataset.csv')\\nX = data[['age', 'sex', 'education', 'income']]\\ny = data['salary']\\n\\n# Split into training and testing sets\\ntrain, test = X[:500], X[500:]\\n\\n# Fit model using training set\\nmodel = reg(X=train.drop('salary', axis=1), y=train['salary'])\\nmodel.fit()\\n\\n# Evaluate model on testing set\\nscore = model.score(test, 'salary')\\nprint(f'Regression score: {score}')\\n```\\n\\nIn this example, we loaded the `dataset.csv` dataset and split it into training and testing sets with a ratio of 50% for each. We then fit the model using the training set and evaluate its performance on the testing set by computing the regression score. The result is printed to the console.\\n\\nTo generate graphs and tables based on the actual data, you can use the `pandas` library. Here's an example:\\n\\n```python\\nimport pandas as pd\\nfrom statsmodels.formula import reg\\n\\n# Load dataset\\ndata = pd.read_csv('dataset.csv')\\nX = data[['age', 'sex', 'education', 'income']]\\ny = data['salary']\\n\\n# Fit model using training set\\nmodel = reg(X=train.drop('salary', axis=1), y=train['salary'])\\nmodel.summary()\\n```\\n\\nIn this example, we loaded the `dataset.csv` dataset and fitted a regression model using the training set. We then printed out the summary of the model using the `summary()` method.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "your_question = \"No. i meant can you do the regreesion analysis and share the result with me? If you can generate graphs and tables then it would be a bonus.\"\n",
    "print(f\"\\nüîç Your question: {your_question}\")\n",
    "ask_ai_question(your_question, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7758dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Your question: Do a regression analysis between age and survival and share the result with me\n",
      "üîç Asking AI: Do a regression analysis between age and survival and share the result with me\n",
      "üìä AI Response: To perform a regression analysis between age and survival using the given dataset, follow these steps:\n",
      "\n",
      "1. Import the dataset into your preferred statistical software or program.\n",
      "2. Examine the data by inspecting the first few rows to ensure that it meets the necessary conditions for a regression analysis.\n",
      "3. Check if there are missing values in the dataset and remove them if necessary.\n",
      "4. Split the dataset into training and testing sets using the 'train_test_split' function from scikit-learn or any other appropriate library.\n",
      "5. Preprocess the data by removing outliers, scaling the variables to a standardized range, and normalizing the features.\n",
      "6. Perform a regression analysis using statistical software or programming language.\n",
      "7. Calculate the correlation coefficient between age and survival and interpret its significance.\n",
      "8. Analyze the results of the regression analysis and draw conclusions based on the data.\n",
      "9. Present the results in a clear and concise manner, including tables, graphs, and visualizations where appropriate.\n",
      "10. Use the insights gained from this analysis to inform future decisions or recommendations related to age and survival.\n",
      "‚è±Ô∏è Time: 32.3 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"To perform a regression analysis between age and survival using the given dataset, follow these steps:\\n\\n1. Import the dataset into your preferred statistical software or program.\\n2. Examine the data by inspecting the first few rows to ensure that it meets the necessary conditions for a regression analysis.\\n3. Check if there are missing values in the dataset and remove them if necessary.\\n4. Split the dataset into training and testing sets using the 'train_test_split' function from scikit-learn or any other appropriate library.\\n5. Preprocess the data by removing outliers, scaling the variables to a standardized range, and normalizing the features.\\n6. Perform a regression analysis using statistical software or programming language.\\n7. Calculate the correlation coefficient between age and survival and interpret its significance.\\n8. Analyze the results of the regression analysis and draw conclusions based on the data.\\n9. Present the results in a clear and concise manner, including tables, graphs, and visualizations where appropriate.\\n10. Use the insights gained from this analysis to inform future decisions or recommendations related to age and survival.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "your_question = \"Do a regression analysis between age and survival and share the result with me\"\n",
    "print(f\"\\nüîç Your question: {your_question}\")\n",
    "ask_ai_question(your_question, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5501d67",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m r2_score, mean_squared_error\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üöÄ Enhanced EDA + Statistical Analysis Setup Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "658dc459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded dataset with 169 rows and 40 columns\n",
      "üìã Columns: ['SL NO', 'DOCTOR_NAME', 'HOSPITAL_NUMBER', 'PATIENT_NAME', 'CONTACTNO', 'DEATH/ ALIVE (7 AUG 2024)', 'DEATH/ ALIVE (OUTSIDE RX DETAILS)', 'status', 'FOLLOW UP STATUS', 'SURGERY DATE', 'Study end time', 'Calculation Time', 'time_in_days', 'time_in_mos', 'TUMOR SIZE', 'SEX', 'AGE', 'LOCATION', 'LOCATION.1', 'LATARALITY', 'HPR DETAILS', 'HPR', 'GRADE', 'PRESS_DIAGNOSIS', 'SURGERY NAME', 'SURGERY TYPE', 'GFAP', 'IDH1/ IDH2', 'ATRX', 'MGMT', 'Mib Lebeling Index', 'RT DOSE', 'RT MODALITY', 'CCRT', 'RT COMPLETION DATE', 'ADJUVANT ChT', 'START DATE', 'END DATE', 'RECC STATUS', 'OS']\n"
     ]
    }
   ],
   "source": [
    "def load_any_dataset(file_path):\n",
    "    \"\"\"Load any dataset (Excel, CSV, etc.)\"\"\"\n",
    "    try:\n",
    "        if file_path.endswith('.xlsx') or file_path.endswith('.xls'):\n",
    "            df = pd.read_excel(file_path)\n",
    "        elif file_path.endswith('.csv'):\n",
    "            df = pd.read_csv(file_path)\n",
    "        else:\n",
    "            print(\"‚ùå Unsupported file format. Use Excel (.xlsx) or CSV (.csv)\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"‚úÖ Loaded dataset with {len(df)} rows and {len(df.columns)} columns\")\n",
    "        print(f\"üìã Columns: {list(df.columns)}\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading dataset: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load your dataset\n",
    "file_path = r\"D:\\Python code\\ollama\\GBM_V1.11.xlsx\"\n",
    "df = load_any_dataset(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61312153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_json_serialize(obj):\n",
    "    \"\"\"Safely serialize objects to JSON, handling datetime and other non-serializable types\"\"\"\n",
    "    if pd.isna(obj):\n",
    "        return None\n",
    "    elif isinstance(obj, (pd.Timestamp, pd.DatetimeTZDtype)):\n",
    "        return str(obj)\n",
    "    elif isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "def perform_simple_regression_analysis(df, x_col, y_col):\n",
    "    \"\"\"Perform simple regression analysis without scikit-learn\"\"\"\n",
    "    try:\n",
    "        # Clean data - remove missing values\n",
    "        clean_df = df[[x_col, y_col]].dropna()\n",
    "        \n",
    "        if len(clean_df) < 10:\n",
    "            return {\"error\": f\"Insufficient data for regression. Only {len(clean_df)} complete cases.\"}\n",
    "        \n",
    "        # Convert to numeric if needed\n",
    "        clean_df[x_col] = pd.to_numeric(clean_df[x_col], errors='coerce')\n",
    "        clean_df[y_col] = pd.to_numeric(clean_df[y_col], errors='coerce')\n",
    "        clean_df = clean_df.dropna()\n",
    "        \n",
    "        if len(clean_df) < 10:\n",
    "            return {\"error\": f\"Insufficient numeric data for regression. Only {len(clean_df)} complete cases.\"}\n",
    "        \n",
    "        # Calculate basic statistics\n",
    "        x_values = clean_df[x_col].values\n",
    "        y_values = clean_df[y_col].values\n",
    "        \n",
    "        # Calculate correlation\n",
    "        correlation = np.corrcoef(x_values, y_values)[0, 1]\n",
    "        \n",
    "        # Calculate basic regression statistics\n",
    "        n = len(x_values)\n",
    "        x_mean = np.mean(x_values)\n",
    "        y_mean = np.mean(y_values)\n",
    "        \n",
    "        # Calculate slope and intercept\n",
    "        numerator = np.sum((x_values - x_mean) * (y_values - y_mean))\n",
    "        denominator = np.sum((x_values - x_mean) ** 2)\n",
    "        \n",
    "        if denominator == 0:\n",
    "            return {\"error\": \"Cannot calculate regression: denominator is zero\"}\n",
    "        \n",
    "        slope = numerator / denominator\n",
    "        intercept = y_mean - slope * x_mean\n",
    "        \n",
    "        # Calculate R-squared\n",
    "        y_pred = slope * x_values + intercept\n",
    "        ss_res = np.sum((y_values - y_pred) ** 2)\n",
    "        ss_tot = np.sum((y_values - y_mean) ** 2)\n",
    "        r_squared = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0\n",
    "        \n",
    "        # Calculate RMSE\n",
    "        rmse = np.sqrt(np.mean((y_values - y_pred) ** 2))\n",
    "        \n",
    "        # Calculate descriptive statistics\n",
    "        x_stats = {\n",
    "            \"mean\": float(np.mean(x_values)),\n",
    "            \"std\": float(np.std(x_values)),\n",
    "            \"min\": float(np.min(x_values)),\n",
    "            \"max\": float(np.max(x_values))\n",
    "        }\n",
    "        \n",
    "        y_stats = {\n",
    "            \"mean\": float(np.mean(y_values)),\n",
    "            \"std\": float(np.std(y_values)),\n",
    "            \"min\": float(np.min(y_values)),\n",
    "            \"max\": float(np.max(y_values))\n",
    "        }\n",
    "        \n",
    "        results = {\n",
    "            \"n_samples\": len(clean_df),\n",
    "            \"x_variable\": x_col,\n",
    "            \"y_variable\": y_col,\n",
    "            \"x_statistics\": x_stats,\n",
    "            \"y_statistics\": y_stats,\n",
    "            \"regression_coefficient\": float(slope),\n",
    "            \"intercept\": float(intercept),\n",
    "            \"r_squared\": float(r_squared),\n",
    "            \"rmse\": float(rmse),\n",
    "            \"correlation_coefficient\": float(correlation),\n",
    "            \"interpretation\": get_simple_regression_interpretation(r_squared, correlation)\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Regression analysis failed: {str(e)}\"}\n",
    "\n",
    "def get_simple_regression_interpretation(r2, correlation):\n",
    "    \"\"\"Get interpretation of regression results\"\"\"\n",
    "    interpretations = []\n",
    "    \n",
    "    # R-squared interpretation\n",
    "    if r2 >= 0.7:\n",
    "        interpretations.append(f\"Strong relationship (R¬≤ = {r2:.3f})\")\n",
    "    elif r2 >= 0.5:\n",
    "        interpretations.append(f\"Moderate relationship (R¬≤ = {r2:.3f})\")\n",
    "    elif r2 >= 0.3:\n",
    "        interpretations.append(f\"Weak relationship (R¬≤ = {r2:.3f})\")\n",
    "    else:\n",
    "        interpretations.append(f\"Very weak relationship (R¬≤ = {r2:.3f})\")\n",
    "    \n",
    "    # Correlation interpretation\n",
    "    if abs(correlation) >= 0.7:\n",
    "        strength = \"strong\"\n",
    "    elif abs(correlation) >= 0.5:\n",
    "        strength = \"moderate\"\n",
    "    elif abs(correlation) >= 0.3:\n",
    "        strength = \"weak\"\n",
    "    else:\n",
    "        strength = \"very weak\"\n",
    "    \n",
    "    direction = \"positive\" if correlation > 0 else \"negative\"\n",
    "    interpretations.append(f\"{strength.capitalize()} {direction} correlation (r = {correlation:.3f})\")\n",
    "    \n",
    "    return interpretations\n",
    "\n",
    "def perform_comprehensive_eda_fixed(df):\n",
    "    \"\"\"Perform comprehensive EDA with proper JSON serialization\"\"\"\n",
    "    print(\"üîç Performing comprehensive EDA...\")\n",
    "    \n",
    "    eda_results = {\n",
    "        \"dataset_overview\": {},\n",
    "        \"numeric_analysis\": {},\n",
    "        \"categorical_analysis\": {},\n",
    "        \"correlation_analysis\": {},\n",
    "        \"missing_data_analysis\": {},\n",
    "        \"key_insights\": []\n",
    "    }\n",
    "    \n",
    "    # 1. Dataset Overview\n",
    "    eda_results[\"dataset_overview\"] = {\n",
    "        \"total_rows\": len(df),\n",
    "        \"total_columns\": len(df.columns),\n",
    "        \"column_names\": list(df.columns),\n",
    "        \"data_types\": {str(k): str(v) for k, v in df.dtypes.to_dict().items()},\n",
    "        \"memory_usage\": float(df.memory_usage(deep=True).sum() / 1024 / 1024)\n",
    "    }\n",
    "    \n",
    "    # 2. Missing Data Analysis\n",
    "    missing_data = df.isnull().sum()\n",
    "    missing_percentage = (missing_data / len(df)) * 100\n",
    "    eda_results[\"missing_data_analysis\"] = {\n",
    "        \"missing_counts\": {str(k): int(v) for k, v in missing_data.to_dict().items()},\n",
    "        \"missing_percentages\": {str(k): float(v) for k, v in missing_percentage.to_dict().items()},\n",
    "        \"columns_with_missing\": [str(col) for col in missing_data[missing_data > 0].index.tolist()]\n",
    "    }\n",
    "    \n",
    "    # 3. Numeric Analysis\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if numeric_columns:\n",
    "        numeric_stats = {}\n",
    "        for col in numeric_columns:\n",
    "            clean_data = df[col].dropna()\n",
    "            if len(clean_data) > 0:\n",
    "                numeric_stats[str(col)] = {\n",
    "                    \"mean\": float(clean_data.mean()),\n",
    "                    \"median\": float(clean_data.median()),\n",
    "                    \"std\": float(clean_data.std()),\n",
    "                    \"min\": float(clean_data.min()),\n",
    "                    \"max\": float(clean_data.max()),\n",
    "                    \"q25\": float(clean_data.quantile(0.25)),\n",
    "                    \"q75\": float(clean_data.quantile(0.75)),\n",
    "                    \"skewness\": float(clean_data.skew()),\n",
    "                    \"missing_count\": int(df[col].isnull().sum()),\n",
    "                    \"n_complete\": len(clean_data)\n",
    "                }\n",
    "        eda_results[\"numeric_analysis\"] = numeric_stats\n",
    "    \n",
    "    # 4. Categorical Analysis\n",
    "    categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    if categorical_columns:\n",
    "        categorical_stats = {}\n",
    "        for col in categorical_columns:\n",
    "            value_counts = df[col].value_counts()\n",
    "            categorical_stats[str(col)] = {\n",
    "                \"unique_values\": int(df[col].nunique()),\n",
    "                \"most_common\": str(value_counts.index[0]) if len(value_counts) > 0 else None,\n",
    "                \"most_common_count\": int(value_counts.iloc[0]) if len(value_counts) > 0 else 0,\n",
    "                \"value_counts\": {str(k): int(v) for k, v in value_counts.head(10).to_dict().items()},\n",
    "                \"missing_count\": int(df[col].isnull().sum())\n",
    "            }\n",
    "        eda_results[\"categorical_analysis\"] = categorical_stats\n",
    "    \n",
    "    # 5. Correlation Analysis\n",
    "    if len(numeric_columns) > 1:\n",
    "        correlation_matrix = df[numeric_columns].corr()\n",
    "        correlations = []\n",
    "        for i in range(len(correlation_matrix.columns)):\n",
    "            for j in range(i+1, len(correlation_matrix.columns)):\n",
    "                col1 = str(correlation_matrix.columns[i])\n",
    "                col2 = str(correlation_matrix.columns[j])\n",
    "                corr_value = correlation_matrix.iloc[i, j]\n",
    "                if not pd.isna(corr_value):\n",
    "                    correlations.append({\n",
    "                        \"column1\": col1,\n",
    "                        \"column2\": col2,\n",
    "                        \"correlation\": float(corr_value)\n",
    "                    })\n",
    "        \n",
    "        correlations.sort(key=lambda x: abs(x[\"correlation\"]), reverse=True)\n",
    "        eda_results[\"correlation_analysis\"] = {\n",
    "            \"top_correlations\": correlations[:10],\n",
    "            \"strong_correlations\": [c for c in correlations if abs(c[\"correlation\"]) > 0.5]\n",
    "        }\n",
    "    \n",
    "    # 6. Key Insights\n",
    "    insights = []\n",
    "    insights.append(f\"Dataset contains {len(df)} records with {len(df.columns)} variables\")\n",
    "    \n",
    "    missing_cols = eda_results[\"missing_data_analysis\"][\"columns_with_missing\"]\n",
    "    if missing_cols:\n",
    "        insights.append(f\"Missing data found in {len(missing_cols)} columns: {missing_cols}\")\n",
    "    \n",
    "    if numeric_columns:\n",
    "        insights.append(f\"Numeric variables: {numeric_columns}\")\n",
    "        for col in numeric_columns[:3]:\n",
    "            if col in eda_results[\"numeric_analysis\"]:\n",
    "                stats = eda_results[\"numeric_analysis\"][col]\n",
    "                insights.append(f\"{col}: mean={stats['mean']:.2f}, range={stats['min']:.2f}-{stats['max']:.2f}\")\n",
    "    \n",
    "    if categorical_columns:\n",
    "        insights.append(f\"Categorical variables: {categorical_columns}\")\n",
    "        for col in categorical_columns[:3]:\n",
    "            if col in eda_results[\"categorical_analysis\"]:\n",
    "                stats = eda_results[\"categorical_analysis\"][col]\n",
    "                insights.append(f\"{col}: {stats['unique_values']} unique values, most common: {stats['most_common']}\")\n",
    "    \n",
    "    if eda_results[\"correlation_analysis\"]:\n",
    "        strong_corr = eda_results[\"correlation_analysis\"][\"strong_correlations\"]\n",
    "        if strong_corr:\n",
    "            insights.append(f\"Strong correlations found: {len(strong_corr)} pairs with |r| > 0.5\")\n",
    "    \n",
    "    eda_results[\"key_insights\"] = insights\n",
    "    \n",
    "    print(f\"‚úÖ EDA Complete! Generated {len(insights)} key insights\")\n",
    "    return eda_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e538896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Performing Exploratory Data Analysis...\n",
      "üîç Performing comprehensive EDA...\n",
      "‚úÖ EDA Complete! Generated 11 key insights\n",
      "\n",
      "üìä Key EDA Insights:\n",
      "1. Dataset contains 169 records with 40 variables\n",
      "2. Missing data found in 16 columns: ['CONTACTNO', 'DEATH/ ALIVE (OUTSIDE RX DETAILS)', 'TUMOR SIZE', 'SURGERY NAME', 'ATRX', 'MGMT', 'Mib Lebeling Index', 'RT DOSE', 'RT MODALITY', 'CCRT', 'RT COMPLETION DATE', 'ADJUVANT ChT', 'START DATE', 'END DATE', 'RECC STATUS', 'OS']\n",
      "3. Numeric variables: ['time_in_days', 'time_in_mos', 'AGE', 'OS']\n",
      "4. time_in_days: mean=748.77, range=-9.00-5294.00\n",
      "5. time_in_mos: mean=24.96, range=-0.30-176.47\n",
      "6. AGE: mean=44.49, range=5.74-79.82\n",
      "7. Categorical variables: ['SL NO', 'DOCTOR_NAME', 'HOSPITAL_NUMBER', 'PATIENT_NAME', 'CONTACTNO', 'DEATH/ ALIVE (7 AUG 2024)', 'DEATH/ ALIVE (OUTSIDE RX DETAILS)', 'status', 'TUMOR SIZE', 'SEX', 'LOCATION', 'LOCATION.1', 'LATARALITY', 'HPR DETAILS', 'HPR', 'GRADE', 'PRESS_DIAGNOSIS', 'SURGERY NAME', 'SURGERY TYPE', 'GFAP', 'IDH1/ IDH2', 'ATRX', 'MGMT', 'Mib Lebeling Index', 'RT DOSE', 'RT MODALITY', 'CCRT', 'RT COMPLETION DATE', 'ADJUVANT ChT', 'START DATE', 'END DATE', 'RECC STATUS']\n",
      "8. SL NO: 169 unique values, most common: 1\n",
      "9. DOCTOR_NAME: 3 unique values, most common: Prof. Dr. Qamruzzaman Chowdhury\n",
      "10. HOSPITAL_NUMBER: 168 unique values, most common: R171031092\n",
      "11. Strong correlations found: 1 pairs with |r| > 0.5\n"
     ]
    }
   ],
   "source": [
    "# Perform comprehensive EDA\n",
    "print(\"üîç Performing Exploratory Data Analysis...\")\n",
    "eda_results = perform_comprehensive_eda_fixed(df)\n",
    "\n",
    "# Display key insights\n",
    "print(\"\\nüìä Key EDA Insights:\")\n",
    "for i, insight in enumerate(eda_results['key_insights'], 1):\n",
    "    print(f\"{i}. {insight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05e08800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_ai_with_statistical_analysis_fixed(question, df, eda_results, model=\"tinyllama:latest\"):\n",
    "    \"\"\"Ask AI question using pre-analyzed EDA and statistical results\"\"\"\n",
    "    try:\n",
    "        # Check if question asks for regression analysis\n",
    "        regression_keywords = ['regression', 'correlation', 'relationship', 'linear']\n",
    "        is_regression_question = any(keyword in question.lower() for keyword in regression_keywords)\n",
    "        \n",
    "        # Perform regression analysis if requested\n",
    "        regression_results = None\n",
    "        if is_regression_question:\n",
    "            # Try to identify age and survival columns\n",
    "            age_cols = [col for col in df.columns if 'age' in col.lower()]\n",
    "            survival_cols = [col for col in df.columns if any(word in col.lower() for word in ['survival', 'death', 'alive', 'os', 'time'])]\n",
    "            \n",
    "            if age_cols and survival_cols:\n",
    "                age_col = age_cols[0]\n",
    "                survival_col = survival_cols[0]\n",
    "                print(f\"üîç Performing regression analysis between {age_col} and {survival_col}...\")\n",
    "                regression_results = perform_simple_regression_analysis(df, age_col, survival_col)\n",
    "        \n",
    "        # Create comprehensive prompt\n",
    "        prompt = f\"\"\"\n",
    "        I have performed comprehensive exploratory data analysis and statistical tests on a dataset. Here are the results:\n",
    "\n",
    "        DATASET OVERVIEW:\n",
    "        - Total rows: {eda_results['dataset_overview']['total_rows']}\n",
    "        - Total columns: {eda_results['dataset_overview']['total_columns']}\n",
    "        - Column names: {eda_results['dataset_overview']['column_names']}\n",
    "        - Data types: {eda_results['dataset_overview']['data_types']}\n",
    "\n",
    "        KEY INSIGHTS FROM EDA:\n",
    "        {chr(10).join(['‚Ä¢ ' + insight for insight in eda_results['key_insights']])}\n",
    "\n",
    "        NUMERIC VARIABLES ANALYSIS:\n",
    "        {json.dumps(eda_results['numeric_analysis'], indent=2) if eda_results['numeric_analysis'] else 'No numeric variables found'}\n",
    "\n",
    "        CATEGORICAL VARIABLES ANALYSIS:\n",
    "        {json.dumps(eda_results['categorical_analysis'], indent=2) if eda_results['categorical_analysis'] else 'No categorical variables found'}\n",
    "\n",
    "        CORRELATION ANALYSIS:\n",
    "        {json.dumps(eda_results['correlation_analysis'], indent=2) if eda_results['correlation_analysis'] else 'No correlation analysis available'}\n",
    "\n",
    "        MISSING DATA:\n",
    "        {json.dumps(eda_results['missing_data_analysis'], indent=2)}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Add regression results if available\n",
    "        if regression_results and 'error' not in regression_results:\n",
    "            prompt += f\"\"\"\n",
    "\n",
    "        REGRESSION ANALYSIS RESULTS:\n",
    "        {json.dumps(regression_results, indent=2)}\n",
    "        \"\"\"\n",
    "        elif regression_results and 'error' in regression_results:\n",
    "            prompt += f\"\"\"\n",
    "\n",
    "        REGRESSION ANALYSIS ERROR:\n",
    "        {regression_results['error']}\n",
    "        \"\"\"\n",
    "        \n",
    "        prompt += f\"\"\"\n",
    "\n",
    "        USER QUESTION: {question}\n",
    "\n",
    "        Based on the above analysis results, please provide a detailed and accurate answer to the user's question. \n",
    "        If regression analysis was performed, interpret the results including R-squared, correlation coefficient, and significance.\n",
    "        Reference specific statistics, correlations, and patterns from the analysis above.\n",
    "        Be precise and use the actual numbers and insights from the analysis.\n",
    "        \"\"\"\n",
    "        \n",
    "        # API call to model\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"stream\": False,\n",
    "            \"options\": {\n",
    "                \"num_ctx\": 2048,\n",
    "                \"num_thread\": 4,\n",
    "                \"temperature\": 0.2\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        print(f\"üîç Asking AI: {question}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        response = requests.post(\n",
    "            \"http://localhost:11434/api/chat\",\n",
    "            json=payload,\n",
    "            timeout=90\n",
    "        )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            content = data.get(\"message\", {}).get(\"content\", \"No response\")\n",
    "            print(f\"üìä AI Response: {content}\")\n",
    "            print(f\"‚è±Ô∏è Time: {end_time - start_time:.1f} seconds\")\n",
    "            return content\n",
    "        else:\n",
    "            print(f\"‚ùå Error: HTTP {response.status_code}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86fced8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Testing enhanced analysis: Do a regression analysis between age and survival and share the result with me\n",
      "üîç Performing regression analysis between AGE and HOSPITAL_NUMBER...\n",
      "üîç Asking AI: Do a regression analysis between age and survival and share the result with me\n",
      "üìä AI Response: Regression analysis is a statistical technique used to predict outcomes based on observed variables. In this case, we are performing a regression analysis between age and survival using the dataset provided.\n",
      "\n",
      "The results of the regression analysis show that age has a significant positive effect on survival (R-squared = 0.591715976331361, correlation coefficient = 0.82). This means that for every increase in age by one unit, the probability of surviving to the end of follow-up is increased by 8.2%.\n",
      "\n",
      "To interpret these results, we can see that older patients have a higher chance of survival than younger ones. This finding is consistent with previous research on cancer survival and suggests that aging may play a role in determining survival outcomes.\n",
      "\n",
      "Regarding the significance of the correlation coefficient, it indicates that there is a strong relationship between age and survival. This means that for every unit increase in age, the probability of surviving to the end of follow-up increases by 8.2%.\n",
      "\n",
      "To further analyze the results, we can examine the statistical patterns and patterns of variation in the data. For example, we can see that there is a positive correlation between age and survival, but this correlation is not significant (p-value = 0.19). This means that while there is a positive relationship between age and survival, it is not statistically significant.\n",
      "\n",
      "In conclusion, the regression analysis performed using the dataset provided shows that age has a significant positive effect on survival. The results are consistent with previous research on cancer survival and suggest that aging may play a role in determining survival outcomes. The significance of the correlation coefficient indicates that there is a strong relationship between age and survival, but this correlation is not statistically significant. Overall, the regression analysis performed using the dataset provided provides insights into the relationship between age and survival, which can be useful for clinical decision-making in cancer treatment.\n",
      "‚è±Ô∏è Time: 66.3 seconds\n"
     ]
    }
   ],
   "source": [
    "# Test with regression question\n",
    "if df is not None:\n",
    "    question = \"Do a regression analysis between age and survival and share the result with me\"\n",
    "    print(f\"\\nüîç Testing enhanced analysis: {question}\")\n",
    "    ask_ai_with_statistical_analysis_fixed(question, df, eda_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a27e5986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ÔøΩÔøΩ Ready for Enhanced AI Analysis!\n",
      "\n",
      "üí° You can now ask any question using:\n",
      "   ask_ai_with_statistical_analysis('Your question here', df, eda_results)\n",
      "\n",
      "Example questions:\n",
      "- 'Do a regression analysis between age and survival'\n",
      "- 'What is the correlation between tumor size and survival time?'\n",
      "- 'Analyze the relationship between age and treatment outcomes'\n",
      "- 'What are the key factors affecting patient survival?'\n",
      "- 'Is there a significant relationship between gender and survival?'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nÔøΩÔøΩ Ready for Enhanced AI Analysis!\")\n",
    "print(\"\\nüí° You can now ask any question using:\")\n",
    "print(\"   ask_ai_with_statistical_analysis('Your question here', df, eda_results)\")\n",
    "print(\"\\nExample questions:\")\n",
    "print(\"- 'Do a regression analysis between age and survival'\")\n",
    "print(\"- 'What is the correlation between tumor size and survival time?'\")\n",
    "print(\"- 'Analyze the relationship between age and treatment outcomes'\")\n",
    "print(\"- 'What are the key factors affecting patient survival?'\")\n",
    "print(\"- 'Is there a significant relationship between gender and survival?'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
